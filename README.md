# ğŸ§  AI Interview for Micro-Expression Recognition

This project is an AI-based interview assistant that analyzes subtle facial micro-expressions from uploaded interview videos using a MobileNetV2 deep learning model.
It provides feedback such as Emotional Positivity Score and Stress/Discomfort Score, helping users or recruiters gain deeper emotional insights during interviews.

## ğŸš€ Features

â¦	Upload an interview video through a simple Flask web interface.
â¦	Detects micro-expressions using a MobileNetV2-based classifier trained on CASME II and DFME datasets.
â¦	Overlays top detected emotions (with confidence %) on the processed video.
â¦	Automatically generates:
  â¦ ğŸ¥ Processed video with emotion labels
  â¦	ğŸ“Š Emotional Positivity and Stress/Discomfort Scores
  â¦	ğŸ“ Downloadable ZIP (includes both video + result summary)

## ğŸ§© Project Structure
FYP Final/

â”‚  deploy(MobileNetV2).py          # Flask app â€“ runs server, processes uploaded videos
â”‚  MobileNetV2.py                  # Model training & evaluation (TensorFlow MobileNetV2)
â”‚  Video_Preprocess(CASME).py      # Dataset preprocessing (CASME II)
â”‚  Video_Preprocess(DFME).py       # Dataset preprocessing (DFME)
â”‚  mobilenet_micro_expression_classifier.keras  # Pre-trained model file
â”‚  index.html                      # Web UI for video upload & analysis
â”‚
â””â”€ static/
   â”œâ”€ uploads/                     # Automatically created folder for raw uploads
   â””â”€ processed/                   # Automatically created folder for results

## ğŸ› ï¸ Requirements

â¦	Windows 10/11 (64-bit)
â¦	Python 3.8 (recommended for TensorFlow 2.10)
â¦	FFmpeg (for MP4 video conversion)
â¦	Internet connection (for initial dependency install)

## âš™ï¸ Installation & Setup (Windows + VS Code)
1ï¸âƒ£ Open Terminal in VS Code inside your project folder:

cd "C:\Users\User\FYP Final"

2ï¸âƒ£ Create Virtual Environment
C:\Users\User\AppData\Local\Programs\Python\Python38\python.exe -m venv cbs_fyp
cbs_fyp\Scripts\activate

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Add Trained Model

Place your trained model file here:

FYP Final\mobilenet_micro_expression_classifier.keras

(Or update the MODEL_PATH variable in deploy(MobileNetV2).py.)

5ï¸âƒ£ Install FFmpeg

Unzip or install FFmpeg so that:

C:\ffmpeg\bin\ffmpeg.exe


Check installation:

ffmpeg -version

6ï¸âƒ£ Run the App
python "deploy(MobileNetV2).py"

You should see:

Model loaded successfully
 * Running on http://127.0.0.1:5000/

7ï¸âƒ£ Use the Web Interface

Open your browser and visit:

http://127.0.0.1:5000

Upload an interview video (MP4/AVI/MOV/MKV, â‰¤100 MB).
After processing, download your results as a ZIP file containing:

â¦	processed_video.mp4 â€” video with detected emotions
â¦	results.txt â€” detailed scores and emotion breakdown

## ğŸ§® How It Works

The video is split into frames.

Each frame is analyzed using MobileNetV2, which predicts one of six emotions:

Disgust, Fear, Happiness, Repression, Sadness, Surprise

Emotion counts are aggregated and normalized.

Final results:

Emotional Positivity Score â†’ higher = more positive emotions

Stress/Discomfort Score â†’ higher = more negative emotions

## ğŸ§° Tech Stack

Python, TensorFlow/Keras, OpenCV, Flask

MobileNetV2 for transfer learning

FFmpeg for video encoding/decoding

CASME II / DFME datasets for training

## ğŸ“ˆ Example Output
Positivity Score: 68.4%
Stress Score: 31.6%

Emotion Counts:
 - happiness: 230
 - surprise: 145
 - sadness: 40
 - repression: 28
 - fear: 22
 - disgust: 18

## ğŸ§‘â€ğŸ’» Author
Chin Bao Sheng
Bachelorâ€™s Final Year Project â€“ AI Interview for Micro-Expression Recognition
